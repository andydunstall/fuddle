# Replication
> :warning: **In progress**

The registry is replicated to every Fuddle node in the cluster. This means:
* Clients can connect to any Fuddle node and stream the full registry
* The cluster can tolerate nodes failing and losing networking with minimal
disruption

Compared to a typical database, the number of members in the registry and the
rate of updates are both very low, so replicating member states to all nodes is
ok.

## Overview
Each member has its own stream to a node in Fuddle which is used to send updates
and heartbeats (see [client.md](./client.md) for details). The Fuddle node that
the members stream is connected to becomes the owner for that member, so is
responsible for propagating updates for that member and verifying the member is
still healthy using the failure detector. When a member reconnects to another
Fuddle node, that node takes ownership of the member.

Every member in the registry is assigned a version by the owner, which can be
used to quickly detect missed updates and resolve conflicts when multiple nodes
believe they are the owner.

When an update is received for a member, or an update is generated by the
failure detector, the owner for the member forwards the update via RPC to all
other nodes in the cluster. Therefore under healthy conditions all Fuddle nodes
should quickly get all member updates.

To handle faults such as networking issues between nodes that could cause missed
updates, each node runs a background replica repair process. Nodes will
periodically select a random node in the cluster and send its known set of
member versions. The receiving node will compare the requested member versions
with its own known versions and send any missed updates. It will also use the
requested member versions to detect any members it doesn’t know or are out of
date and request those missed updates.

## Versioning
Each member is assigned a version by its owner. The version contains the owner
ID, a timestamp (UNIX milliseconds) and a counter.

The counter is used to order updates that happen in the same millisecond on the
same owner. So a node will track the last version assigned to a member, and if
the next version is in the same millisecond, it will increment the counter,
otherwise the counter is reset to 0.

Note using timestamps requires all Fuddle nodes to have synchronised clocks to
minimise disruption. However, since each node attempts to take ownership of a
member whenever it receives a heartbeat from that member, even with clock skew
ownership should eventually be correct.

## Forward Updates
Replicas forward updates to members they own to all other nodes in the cluster.

Since each member update is versioned, the order of updates doesn’t matter as
out of date updates are discarded. This also means updates are idempotent.

The number of nodes in the cluster should be small (such as 3 to 5), so
forwarding updates to every other node isn’t much work.

If a node is unreachable, the node will retry for 30 seconds (with backoff). If
after 30 seconds the update still can’t be sent, it will be discarded.

Also if the queue of updates to be sent to a node gets too large, the oldest
updates will be discarded.

If nodes miss updates they will have to repair their state using replica repair,
described below.

## Replica Repair
As described above, under normal conditions updates are forwarded to all other
nodes. However when faults occur and updates cannot be sent, node’s registry
states could end up out of sync. Therefore a background process runs where
nodes periodically verify their states match and send any missed updates.

Replica repair is similar to the Scuttlebutt protocol. Each node periodically
selects a random node and sends the node its known member versions, called a
digest. The size of the digest is limited so if the number of members is too
large to fit in the digest, a random subset will be selected instead.

When a node receives a digest request, it compares the digest with its known
member versions and sends any updates the sender is missing. It will also use
the digest to detect any updates it's missing (either due to being out of date
or discovering unknown members), which it makes a priority to request when it
next performs replica repair.

Note when nodes synchronise via replica repair, they can respond with any known
members, not just the members they own.

### Handling Left Members
When a member leaves the registry, its liveness status is set to `left` and is
assigned an expiry of when the member should be removed.

By assigning an expiry to left members, we avoid members being resurrected.
Such as if node A deletes member `foo`, but then synchronises with node B who
has not deleted the member yet so sends the member `foo` to node A.

To avoid this, whenever an update is received, if the member has a liveness
status of `left` and has expired, the update is discarded.

### Future Improvements
Since in most cases the difference between two nodes should be small, the
digest often contains a lot of redundant information. Also since the digest
size is limited, in a registry with a large number of members only a random
subset of versions may be included which requires more rounds of replica repair
to synchronise states.

Therefore this can be improved by sending a structure similar to a Merkle tree,
so the registry is organised into a hierarchy (such as with levels for member
service, locality, owner etc), where a hash is maintained for each branch. Then
only a small number of hashes needs to be sent to detect discrepancies, then if
there are differences, only the member versions for that subset of the registry
needs to be sent.

## Node Failure
This section describes how Fuddle handles nodes leaving the cluster, either due
to crashing or a network partition. Note under healthy conditions a leaving
node will shed its connections and members before leaving, so this only applies
when a fault occurs.

When a node becomes unreachable, the gossip failure detector will detect it has
left the cluster. We use SWIM as the gossip protocol and failure detector,
which checks whether other nodes in the cluster can reach the suspected node.
So if there is a partition between nodes A and B, but not between A and C, and
C and B, then the nodes won’t consider each other down, so they can still
exchange updates via replica repair as described above.

If the node is down or loses all networking, all healthy members should
reconnect to another node before the `heartbeat_timeout`.

Therefore after a node is considered down for the `heartbeat_timeout`, all
other nodes try to take ownership of any members still owned by the down node.
If those members are considered `up`, then will be marked `down` (as they
failed to reconnect to another node before the `heartbeat_timeout`). Otherwise
if the members are already considered `down` or `left`, the node takes
ownership but doesn’t modify its state.

Nodes may end up competing for ownership, but they should quickly converge.
Since the member is considered `down` or `left` anyway it doesn’t really matter.

Note its possible a node could lose networking to other nodes in the cluster,
but can still communicate with its connected members. Such as if there is a
partition between availability zones.

In this case multiple nodes could believe they are the owner, with one owner
marking the member as `up` (as the member is still connected), and another
marking the member as `down`.

To avoid the ‘correct’ owner losing its ownership, nodes will track the last
contact they have with the member (either heartbeats or updates), then discard
any updates whose timestamp is less than the last contact and take back
ownership by updating the member version with the current timestamp.
